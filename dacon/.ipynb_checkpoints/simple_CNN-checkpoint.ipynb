{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "submission = pd.read_csv('./submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = (train[[str(i) for i in range(784)]]/255.).values.reshape(-1,28,28,1)\n",
    "y_train_full = to_categorical(train['digit'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 10,\n",
    "    zoom_range = 0.10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow(\n",
    "    X_train_full, y_train_full,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow(\n",
    "    X_train_full, y_train_full,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_full[:1536]\n",
    "y_train = y_train_full[:1536]\n",
    "X_val = X_train_full[1536:]\n",
    "y_val = y_train_full[1536:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=(28,28,1))\n",
    "conv_1 = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_)\n",
    "pool_1 = layers.MaxPooling2D(pool_size=(2,2))(conv_1)\n",
    "drop_1 = layers.Dropout(0.25)(pool_1)\n",
    "\n",
    "conv_2 = layers.Conv2D(64,kernel_size=3, padding=\"same\", activation=\"relu\")(drop_1)\n",
    "pool_2 = layers.MaxPooling2D(pool_size=(2,2))(conv_2)\n",
    "drop_2 = layers.Dropout(0.25)(pool_2)\n",
    "\n",
    "conv_3 = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(drop_2)\n",
    "pool_3 = layers.MaxPooling2D(pool_size=(2,2))(conv_3)\n",
    "drop_3 = layers.Dropout(0.25)(pool_3)\n",
    "\n",
    "x = layers.Flatten()(drop_3)\n",
    "dense = layers.Dense(256, activation=\"relu\")(x)\n",
    "drop_4 = layers.Dropout(0.25)(dense)\n",
    "output= layers.Dense(10, activation = \"softmax\")(drop_4)\n",
    "\n",
    "base_model = models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2 = layers.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_2)\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output_2 = layers.Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "#base_model2 = models.Model(inputs=[input_2], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = models.Model(inputs=[input_2], outputs=[output_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 52 steps, validate for 13 steps\n",
      "Epoch 1/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5062 - accuracy: 0.8371 - val_loss: 0.6612 - val_accuracy: 0.8068\n",
      "Epoch 2/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5169 - accuracy: 0.8206 - val_loss: 0.5506 - val_accuracy: 0.8191\n",
      "Epoch 3/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5136 - accuracy: 0.8225 - val_loss: 0.5078 - val_accuracy: 0.8362\n",
      "Epoch 4/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5392 - accuracy: 0.8176 - val_loss: 0.6719 - val_accuracy: 0.7800\n",
      "Epoch 5/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5114 - accuracy: 0.8212 - val_loss: 0.5826 - val_accuracy: 0.8117\n",
      "Epoch 6/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5343 - accuracy: 0.8249 - val_loss: 0.6147 - val_accuracy: 0.8044\n",
      "Epoch 7/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5132 - accuracy: 0.8255 - val_loss: 0.5664 - val_accuracy: 0.8093\n",
      "Epoch 8/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5286 - accuracy: 0.8182 - val_loss: 0.5866 - val_accuracy: 0.8044\n",
      "Epoch 9/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4924 - accuracy: 0.8389 - val_loss: 0.5811 - val_accuracy: 0.8240\n",
      "Epoch 10/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4958 - accuracy: 0.8225 - val_loss: 0.6237 - val_accuracy: 0.7946\n",
      "Epoch 11/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4570 - accuracy: 0.8511 - val_loss: 0.5905 - val_accuracy: 0.8068\n",
      "Epoch 12/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5278 - accuracy: 0.8322 - val_loss: 0.6677 - val_accuracy: 0.7873\n",
      "Epoch 13/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4636 - accuracy: 0.8438 - val_loss: 0.6144 - val_accuracy: 0.7971\n",
      "Epoch 14/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4928 - accuracy: 0.8462 - val_loss: 0.5190 - val_accuracy: 0.8386\n",
      "Epoch 15/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.8328 - val_loss: 0.6509 - val_accuracy: 0.7971\n",
      "Epoch 16/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4975 - accuracy: 0.8353 - val_loss: 0.5558 - val_accuracy: 0.8337\n",
      "Epoch 17/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4829 - accuracy: 0.8511 - val_loss: 0.6563 - val_accuracy: 0.7897\n",
      "Epoch 18/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5146 - accuracy: 0.8316 - val_loss: 0.5658 - val_accuracy: 0.7995\n",
      "Epoch 19/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4860 - accuracy: 0.8340 - val_loss: 0.6211 - val_accuracy: 0.7751\n",
      "Epoch 20/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5201 - accuracy: 0.8298 - val_loss: 0.6310 - val_accuracy: 0.7848\n",
      "Epoch 21/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5260 - accuracy: 0.8328 - val_loss: 0.5843 - val_accuracy: 0.8142\n",
      "Epoch 22/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4939 - accuracy: 0.8334 - val_loss: 0.6262 - val_accuracy: 0.7873\n",
      "Epoch 23/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4970 - accuracy: 0.8365 - val_loss: 0.6245 - val_accuracy: 0.7971\n",
      "Epoch 24/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4881 - accuracy: 0.8408 - val_loss: 0.4988 - val_accuracy: 0.8240\n",
      "Epoch 25/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5090 - accuracy: 0.8377 - val_loss: 0.5890 - val_accuracy: 0.8044\n",
      "Epoch 26/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4682 - accuracy: 0.8438 - val_loss: 0.5809 - val_accuracy: 0.8142\n",
      "Epoch 27/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5088 - accuracy: 0.8212 - val_loss: 0.5605 - val_accuracy: 0.8117\n",
      "Epoch 28/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4963 - accuracy: 0.8389 - val_loss: 0.5779 - val_accuracy: 0.8093\n",
      "Epoch 29/10000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.5006 - accuracy: 0.8273 - val_loss: 0.5368 - val_accuracy: 0.7946\n",
      "Epoch 30/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4585 - accuracy: 0.8603 - val_loss: 0.5550 - val_accuracy: 0.8068\n",
      "Epoch 31/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4806 - accuracy: 0.8432 - val_loss: 0.8838 - val_accuracy: 0.7677\n",
      "Epoch 32/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4845 - accuracy: 0.8316 - val_loss: 0.5541 - val_accuracy: 0.8191\n",
      "Epoch 33/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5274 - accuracy: 0.8334 - val_loss: 0.5742 - val_accuracy: 0.8093\n",
      "Epoch 34/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4773 - accuracy: 0.8426 - val_loss: 0.6010 - val_accuracy: 0.7922\n",
      "Epoch 35/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5231 - accuracy: 0.8377 - val_loss: 0.5934 - val_accuracy: 0.8117\n",
      "Epoch 36/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5113 - accuracy: 0.8353 - val_loss: 0.5528 - val_accuracy: 0.8240\n",
      "Epoch 37/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4685 - accuracy: 0.8536 - val_loss: 0.6141 - val_accuracy: 0.7922\n",
      "Epoch 38/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4330 - accuracy: 0.8475 - val_loss: 0.5325 - val_accuracy: 0.8264\n",
      "Epoch 39/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4847 - accuracy: 0.8389 - val_loss: 0.5367 - val_accuracy: 0.8289\n",
      "Epoch 40/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5099 - accuracy: 0.8279 - val_loss: 0.5511 - val_accuracy: 0.8215\n",
      "Epoch 41/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4803 - accuracy: 0.8432 - val_loss: 0.5377 - val_accuracy: 0.8044\n",
      "Epoch 42/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4624 - accuracy: 0.8475 - val_loss: 0.5839 - val_accuracy: 0.8020\n",
      "Epoch 43/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4897 - accuracy: 0.8316 - val_loss: 0.5662 - val_accuracy: 0.8142\n",
      "Epoch 44/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4891 - accuracy: 0.8456 - val_loss: 0.6492 - val_accuracy: 0.7653\n",
      "Epoch 45/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4594 - accuracy: 0.8426 - val_loss: 0.6709 - val_accuracy: 0.7897\n",
      "Epoch 46/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4643 - accuracy: 0.8585 - val_loss: 0.5253 - val_accuracy: 0.8264\n",
      "Epoch 47/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4575 - accuracy: 0.8469 - val_loss: 0.5353 - val_accuracy: 0.8093\n",
      "Epoch 48/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4327 - accuracy: 0.8536 - val_loss: 0.5437 - val_accuracy: 0.8191\n",
      "Epoch 49/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4674 - accuracy: 0.8505 - val_loss: 0.5348 - val_accuracy: 0.8337\n",
      "Epoch 50/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5062 - accuracy: 0.8426 - val_loss: 0.5625 - val_accuracy: 0.8117\n",
      "Epoch 51/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4683 - accuracy: 0.8487 - val_loss: 0.5653 - val_accuracy: 0.8093\n",
      "Epoch 52/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4534 - accuracy: 0.8517 - val_loss: 0.5598 - val_accuracy: 0.8093\n",
      "Epoch 53/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4946 - accuracy: 0.8371 - val_loss: 0.5785 - val_accuracy: 0.8142\n",
      "Epoch 54/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4750 - accuracy: 0.8523 - val_loss: 0.5527 - val_accuracy: 0.8093\n",
      "Epoch 55/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4526 - accuracy: 0.8542 - val_loss: 0.5346 - val_accuracy: 0.8386\n",
      "Epoch 56/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5195 - accuracy: 0.8353 - val_loss: 0.5614 - val_accuracy: 0.8142\n",
      "Epoch 57/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4763 - accuracy: 0.8371 - val_loss: 0.5488 - val_accuracy: 0.7995\n",
      "Epoch 58/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4679 - accuracy: 0.8450 - val_loss: 0.5491 - val_accuracy: 0.8020\n",
      "Epoch 59/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4335 - accuracy: 0.8542 - val_loss: 0.4972 - val_accuracy: 0.8215\n",
      "Epoch 60/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4168 - accuracy: 0.8633 - val_loss: 0.5167 - val_accuracy: 0.8386\n",
      "Epoch 61/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4289 - accuracy: 0.8475 - val_loss: 0.4609 - val_accuracy: 0.8362\n",
      "Epoch 62/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4362 - accuracy: 0.8511 - val_loss: 0.6053 - val_accuracy: 0.7946\n",
      "Epoch 63/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4464 - accuracy: 0.8572 - val_loss: 0.6103 - val_accuracy: 0.8093\n",
      "Epoch 64/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4192 - accuracy: 0.8542 - val_loss: 0.5056 - val_accuracy: 0.8337\n",
      "Epoch 65/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4499 - accuracy: 0.8469 - val_loss: 0.5472 - val_accuracy: 0.8215\n",
      "Epoch 66/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4784 - accuracy: 0.8383 - val_loss: 0.6743 - val_accuracy: 0.7726\n",
      "Epoch 67/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4314 - accuracy: 0.8609 - val_loss: 0.5387 - val_accuracy: 0.8337\n",
      "Epoch 68/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4787 - accuracy: 0.8377 - val_loss: 0.5638 - val_accuracy: 0.8044\n",
      "Epoch 69/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4590 - accuracy: 0.8530 - val_loss: 0.5491 - val_accuracy: 0.8142\n",
      "Epoch 70/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4550 - accuracy: 0.8475 - val_loss: 0.5865 - val_accuracy: 0.7946\n",
      "Epoch 71/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4605 - accuracy: 0.8401 - val_loss: 0.5376 - val_accuracy: 0.8215\n",
      "Epoch 72/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4638 - accuracy: 0.8511 - val_loss: 0.5440 - val_accuracy: 0.8264\n",
      "Epoch 73/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4407 - accuracy: 0.8511 - val_loss: 0.5855 - val_accuracy: 0.8020\n",
      "Epoch 74/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4887 - accuracy: 0.8426 - val_loss: 0.5449 - val_accuracy: 0.7995\n",
      "Epoch 75/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4304 - accuracy: 0.8530 - val_loss: 0.5738 - val_accuracy: 0.8020\n",
      "Epoch 76/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4703 - accuracy: 0.8487 - val_loss: 0.5658 - val_accuracy: 0.8020\n",
      "Epoch 77/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4607 - accuracy: 0.8469 - val_loss: 0.6213 - val_accuracy: 0.8020\n",
      "Epoch 78/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4267 - accuracy: 0.8505 - val_loss: 0.5972 - val_accuracy: 0.7946\n",
      "Epoch 79/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4550 - accuracy: 0.8365 - val_loss: 0.4789 - val_accuracy: 0.8484\n",
      "Epoch 80/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4286 - accuracy: 0.8609 - val_loss: 0.6055 - val_accuracy: 0.7971\n",
      "Epoch 81/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4724 - accuracy: 0.8267 - val_loss: 0.5123 - val_accuracy: 0.8215\n",
      "Epoch 82/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4895 - accuracy: 0.8401 - val_loss: 0.6289 - val_accuracy: 0.7848\n",
      "Epoch 83/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4556 - accuracy: 0.8408 - val_loss: 0.5479 - val_accuracy: 0.8191\n",
      "Epoch 84/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4268 - accuracy: 0.8560 - val_loss: 0.5254 - val_accuracy: 0.8264\n",
      "Epoch 85/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4448 - accuracy: 0.8536 - val_loss: 0.5576 - val_accuracy: 0.8020\n",
      "Epoch 86/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4336 - accuracy: 0.8487 - val_loss: 0.5462 - val_accuracy: 0.8166\n",
      "Epoch 87/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4236 - accuracy: 0.8615 - val_loss: 0.5801 - val_accuracy: 0.8215\n",
      "Epoch 88/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4005 - accuracy: 0.8688 - val_loss: 0.5166 - val_accuracy: 0.8093\n",
      "Epoch 89/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4088 - accuracy: 0.8810 - val_loss: 0.5068 - val_accuracy: 0.8215\n",
      "Epoch 90/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4332 - accuracy: 0.8499 - val_loss: 0.5085 - val_accuracy: 0.8240\n",
      "Epoch 91/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4303 - accuracy: 0.8585 - val_loss: 0.5015 - val_accuracy: 0.8362\n",
      "Epoch 92/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3948 - accuracy: 0.8646 - val_loss: 0.6776 - val_accuracy: 0.7922\n",
      "Epoch 93/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4258 - accuracy: 0.8633 - val_loss: 0.5402 - val_accuracy: 0.8215\n",
      "Epoch 94/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3972 - accuracy: 0.8761 - val_loss: 0.4889 - val_accuracy: 0.8337\n",
      "Epoch 95/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4527 - accuracy: 0.8493 - val_loss: 0.5295 - val_accuracy: 0.8093\n",
      "Epoch 96/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4433 - accuracy: 0.8548 - val_loss: 0.5272 - val_accuracy: 0.8142\n",
      "Epoch 97/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4374 - accuracy: 0.8493 - val_loss: 0.5892 - val_accuracy: 0.8240\n",
      "Epoch 98/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4279 - accuracy: 0.8609 - val_loss: 0.5417 - val_accuracy: 0.8240\n",
      "Epoch 99/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4198 - accuracy: 0.8578 - val_loss: 0.5072 - val_accuracy: 0.8289\n",
      "Epoch 100/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4346 - accuracy: 0.8646 - val_loss: 0.5712 - val_accuracy: 0.7848\n",
      "Epoch 101/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4200 - accuracy: 0.8609 - val_loss: 0.5287 - val_accuracy: 0.8264\n",
      "Epoch 102/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3913 - accuracy: 0.8700 - val_loss: 0.5288 - val_accuracy: 0.8240\n",
      "Epoch 103/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4366 - accuracy: 0.8585 - val_loss: 0.6049 - val_accuracy: 0.8020\n",
      "Epoch 104/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4622 - accuracy: 0.8493 - val_loss: 0.5219 - val_accuracy: 0.8337\n",
      "Epoch 105/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8530 - val_loss: 0.5497 - val_accuracy: 0.8240\n",
      "Epoch 106/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4340 - accuracy: 0.8652 - val_loss: 0.5554 - val_accuracy: 0.8264\n",
      "Epoch 107/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3986 - accuracy: 0.8670 - val_loss: 0.5268 - val_accuracy: 0.8215\n",
      "Epoch 108/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4441 - accuracy: 0.8572 - val_loss: 0.5345 - val_accuracy: 0.8484\n",
      "Epoch 109/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4087 - accuracy: 0.8578 - val_loss: 0.5688 - val_accuracy: 0.8166\n",
      "Epoch 110/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4273 - accuracy: 0.8603 - val_loss: 0.4993 - val_accuracy: 0.8240\n",
      "Epoch 111/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4230 - accuracy: 0.8646 - val_loss: 0.5557 - val_accuracy: 0.7971\n",
      "Epoch 112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4123 - accuracy: 0.8603 - val_loss: 0.5496 - val_accuracy: 0.8264\n",
      "Epoch 113/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4266 - accuracy: 0.8719 - val_loss: 0.5422 - val_accuracy: 0.8166\n",
      "Epoch 114/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4325 - accuracy: 0.8585 - val_loss: 0.5042 - val_accuracy: 0.8215\n",
      "Epoch 115/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4373 - accuracy: 0.8548 - val_loss: 0.5547 - val_accuracy: 0.8044\n",
      "Epoch 116/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4737 - accuracy: 0.8456 - val_loss: 0.5273 - val_accuracy: 0.7995\n",
      "Epoch 117/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4747 - accuracy: 0.8456 - val_loss: 0.5584 - val_accuracy: 0.7946\n",
      "Epoch 118/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4585 - accuracy: 0.8578 - val_loss: 0.5683 - val_accuracy: 0.7946\n",
      "Epoch 119/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4164 - accuracy: 0.8621 - val_loss: 0.5144 - val_accuracy: 0.8264\n",
      "Epoch 120/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4442 - accuracy: 0.8517 - val_loss: 0.5220 - val_accuracy: 0.8337\n",
      "Epoch 121/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8475 - val_loss: 0.5849 - val_accuracy: 0.8020\n",
      "Epoch 122/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4129 - accuracy: 0.8523 - val_loss: 0.5245 - val_accuracy: 0.8240\n",
      "Epoch 123/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4129 - accuracy: 0.8621 - val_loss: 0.5348 - val_accuracy: 0.8191\n",
      "Epoch 124/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4566 - accuracy: 0.8438 - val_loss: 0.5603 - val_accuracy: 0.7995\n",
      "Epoch 125/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4141 - accuracy: 0.8597 - val_loss: 0.5845 - val_accuracy: 0.8044\n",
      "Epoch 126/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4089 - accuracy: 0.8670 - val_loss: 0.5197 - val_accuracy: 0.8191\n",
      "Epoch 127/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4659 - accuracy: 0.8389 - val_loss: 0.5463 - val_accuracy: 0.8142\n",
      "Epoch 128/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4423 - accuracy: 0.8481 - val_loss: 0.5651 - val_accuracy: 0.7995\n",
      "Epoch 129/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3621 - accuracy: 0.8731 - val_loss: 0.5329 - val_accuracy: 0.8240\n",
      "Epoch 130/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4306 - accuracy: 0.8560 - val_loss: 0.4958 - val_accuracy: 0.8240\n",
      "Epoch 131/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4007 - accuracy: 0.8737 - val_loss: 0.5052 - val_accuracy: 0.8337\n",
      "Epoch 132/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4020 - accuracy: 0.8621 - val_loss: 0.5197 - val_accuracy: 0.8215\n",
      "Epoch 133/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8560 - val_loss: 0.5271 - val_accuracy: 0.8337\n",
      "Epoch 134/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8615 - val_loss: 0.4893 - val_accuracy: 0.8509\n",
      "Epoch 135/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4027 - accuracy: 0.8560 - val_loss: 0.4951 - val_accuracy: 0.8240\n",
      "Epoch 136/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4406 - accuracy: 0.8499 - val_loss: 0.4755 - val_accuracy: 0.8313\n",
      "Epoch 137/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4261 - accuracy: 0.8627 - val_loss: 0.5481 - val_accuracy: 0.8191\n",
      "Epoch 138/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4254 - accuracy: 0.8554 - val_loss: 0.6083 - val_accuracy: 0.8093\n",
      "Epoch 139/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4094 - accuracy: 0.8700 - val_loss: 0.5417 - val_accuracy: 0.8020\n",
      "Epoch 140/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3717 - accuracy: 0.8688 - val_loss: 0.4981 - val_accuracy: 0.8484\n",
      "Epoch 141/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4211 - accuracy: 0.8530 - val_loss: 0.4614 - val_accuracy: 0.8582\n",
      "Epoch 142/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4069 - accuracy: 0.8627 - val_loss: 0.6188 - val_accuracy: 0.7897\n",
      "Epoch 143/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3725 - accuracy: 0.8749 - val_loss: 0.5196 - val_accuracy: 0.8362\n",
      "Epoch 144/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4035 - accuracy: 0.8725 - val_loss: 0.5162 - val_accuracy: 0.8142\n",
      "Epoch 145/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4188 - accuracy: 0.8676 - val_loss: 0.5516 - val_accuracy: 0.8142\n",
      "Epoch 146/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3894 - accuracy: 0.8633 - val_loss: 0.4852 - val_accuracy: 0.8386\n",
      "Epoch 147/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4275 - accuracy: 0.8713 - val_loss: 0.6233 - val_accuracy: 0.7751\n",
      "Epoch 148/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4107 - accuracy: 0.8603 - val_loss: 0.5568 - val_accuracy: 0.7971\n",
      "Epoch 149/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4143 - accuracy: 0.8761 - val_loss: 0.5024 - val_accuracy: 0.8191\n",
      "Epoch 150/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4075 - accuracy: 0.8652 - val_loss: 0.5444 - val_accuracy: 0.8142\n",
      "Epoch 151/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4554 - accuracy: 0.8487 - val_loss: 0.5223 - val_accuracy: 0.8240\n",
      "Epoch 152/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8664 - val_loss: 0.5714 - val_accuracy: 0.8289\n",
      "Epoch 153/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4296 - accuracy: 0.8585 - val_loss: 0.5846 - val_accuracy: 0.7971\n",
      "Epoch 154/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4285 - accuracy: 0.8707 - val_loss: 0.5017 - val_accuracy: 0.8191\n",
      "Epoch 155/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3893 - accuracy: 0.8621 - val_loss: 0.5194 - val_accuracy: 0.8117\n",
      "Epoch 156/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4340 - accuracy: 0.8530 - val_loss: 0.5649 - val_accuracy: 0.8020\n",
      "Epoch 157/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4230 - accuracy: 0.8627 - val_loss: 0.5763 - val_accuracy: 0.7873\n",
      "Epoch 158/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4523 - accuracy: 0.8505 - val_loss: 0.5588 - val_accuracy: 0.8142\n",
      "Epoch 159/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4215 - accuracy: 0.8627 - val_loss: 0.5462 - val_accuracy: 0.8117\n",
      "Epoch 160/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4157 - accuracy: 0.8560 - val_loss: 0.5230 - val_accuracy: 0.8191\n",
      "Epoch 161/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4432 - accuracy: 0.8548 - val_loss: 0.5674 - val_accuracy: 0.8044\n",
      "Epoch 162/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3864 - accuracy: 0.8694 - val_loss: 0.5427 - val_accuracy: 0.8093\n",
      "Epoch 163/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.8737 - val_loss: 0.5674 - val_accuracy: 0.7995\n",
      "Epoch 164/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4073 - accuracy: 0.8627 - val_loss: 0.5325 - val_accuracy: 0.8215\n",
      "Epoch 165/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3815 - accuracy: 0.8737 - val_loss: 0.5429 - val_accuracy: 0.8337\n",
      "Epoch 166/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4213 - accuracy: 0.8646 - val_loss: 0.6234 - val_accuracy: 0.7824\n",
      "Epoch 167/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.8633 - val_loss: 0.5794 - val_accuracy: 0.7946\n",
      "Epoch 168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4576 - accuracy: 0.8554 - val_loss: 0.5574 - val_accuracy: 0.8044\n",
      "Epoch 169/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3963 - accuracy: 0.8652 - val_loss: 0.5311 - val_accuracy: 0.8362\n",
      "Epoch 170/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3940 - accuracy: 0.8688 - val_loss: 0.4774 - val_accuracy: 0.8215\n",
      "Epoch 171/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4040 - accuracy: 0.8694 - val_loss: 0.5077 - val_accuracy: 0.8411\n",
      "Epoch 172/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4142 - accuracy: 0.8627 - val_loss: 0.5364 - val_accuracy: 0.8191\n",
      "Epoch 173/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4116 - accuracy: 0.8615 - val_loss: 0.4745 - val_accuracy: 0.8386\n",
      "Epoch 174/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3847 - accuracy: 0.8676 - val_loss: 0.5258 - val_accuracy: 0.8191\n",
      "Epoch 175/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4219 - accuracy: 0.8566 - val_loss: 0.5483 - val_accuracy: 0.8117\n",
      "Epoch 176/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3999 - accuracy: 0.8761 - val_loss: 0.4869 - val_accuracy: 0.8435\n",
      "Epoch 177/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4082 - accuracy: 0.8725 - val_loss: 0.5587 - val_accuracy: 0.8264\n",
      "Epoch 178/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4479 - accuracy: 0.8566 - val_loss: 0.4951 - val_accuracy: 0.8191\n",
      "Epoch 179/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4081 - accuracy: 0.8682 - val_loss: 0.4956 - val_accuracy: 0.8460\n",
      "Epoch 180/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3938 - accuracy: 0.8731 - val_loss: 0.4926 - val_accuracy: 0.8240\n",
      "Epoch 181/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4027 - accuracy: 0.8786 - val_loss: 0.5242 - val_accuracy: 0.8460\n",
      "Epoch 182/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4518 - accuracy: 0.8554 - val_loss: 0.5759 - val_accuracy: 0.8142\n",
      "Epoch 183/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4178 - accuracy: 0.8591 - val_loss: 0.5712 - val_accuracy: 0.8142\n",
      "Epoch 184/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3856 - accuracy: 0.8768 - val_loss: 0.5219 - val_accuracy: 0.8289\n",
      "Epoch 185/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3382 - accuracy: 0.8877 - val_loss: 0.5401 - val_accuracy: 0.8166\n",
      "Epoch 186/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8609 - val_loss: 0.6384 - val_accuracy: 0.8020\n",
      "Epoch 187/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4385 - accuracy: 0.8572 - val_loss: 0.5535 - val_accuracy: 0.8289\n",
      "Epoch 188/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3908 - accuracy: 0.8688 - val_loss: 0.5396 - val_accuracy: 0.8093\n",
      "Epoch 189/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4164 - accuracy: 0.8652 - val_loss: 0.5155 - val_accuracy: 0.8093\n",
      "Epoch 190/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3735 - accuracy: 0.8646 - val_loss: 0.5348 - val_accuracy: 0.8337\n",
      "Epoch 191/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4405 - accuracy: 0.8517 - val_loss: 0.4930 - val_accuracy: 0.8289\n",
      "Epoch 192/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3874 - accuracy: 0.8731 - val_loss: 0.5589 - val_accuracy: 0.8166\n",
      "Epoch 193/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3794 - accuracy: 0.8774 - val_loss: 0.4999 - val_accuracy: 0.8533\n",
      "Epoch 194/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3780 - accuracy: 0.8737 - val_loss: 0.5639 - val_accuracy: 0.8044\n",
      "Epoch 195/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4007 - accuracy: 0.8743 - val_loss: 0.5544 - val_accuracy: 0.8215\n",
      "Epoch 196/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3890 - accuracy: 0.8682 - val_loss: 0.4850 - val_accuracy: 0.8264\n",
      "Epoch 197/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3987 - accuracy: 0.8652 - val_loss: 0.4960 - val_accuracy: 0.8142\n",
      "Epoch 198/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4358 - accuracy: 0.8652 - val_loss: 0.5796 - val_accuracy: 0.7971\n",
      "Epoch 199/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3821 - accuracy: 0.8700 - val_loss: 0.5137 - val_accuracy: 0.8289\n",
      "Epoch 200/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4149 - accuracy: 0.8585 - val_loss: 0.5715 - val_accuracy: 0.8191\n",
      "Epoch 201/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3924 - accuracy: 0.8688 - val_loss: 0.5145 - val_accuracy: 0.8411\n",
      "Epoch 202/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4153 - accuracy: 0.8639 - val_loss: 0.5539 - val_accuracy: 0.8215\n",
      "Epoch 203/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3822 - accuracy: 0.8749 - val_loss: 0.5402 - val_accuracy: 0.8044\n",
      "Epoch 204/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8652 - val_loss: 0.5257 - val_accuracy: 0.8289\n",
      "Epoch 205/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3418 - accuracy: 0.8822 - val_loss: 0.5020 - val_accuracy: 0.8191\n",
      "Epoch 206/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4164 - accuracy: 0.8566 - val_loss: 0.4809 - val_accuracy: 0.8435\n",
      "Epoch 207/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4347 - accuracy: 0.8633 - val_loss: 0.5065 - val_accuracy: 0.8337\n",
      "Epoch 208/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4250 - accuracy: 0.8597 - val_loss: 0.5026 - val_accuracy: 0.8289\n",
      "Epoch 209/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4139 - accuracy: 0.8774 - val_loss: 0.5437 - val_accuracy: 0.8191\n",
      "Epoch 210/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4187 - accuracy: 0.8523 - val_loss: 0.5299 - val_accuracy: 0.8264\n",
      "Epoch 211/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4056 - accuracy: 0.8676 - val_loss: 0.5379 - val_accuracy: 0.8215\n",
      "Epoch 212/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3947 - accuracy: 0.8768 - val_loss: 0.6261 - val_accuracy: 0.8117\n",
      "Epoch 213/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4212 - accuracy: 0.8694 - val_loss: 0.5678 - val_accuracy: 0.8068\n",
      "Epoch 214/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4101 - accuracy: 0.8646 - val_loss: 0.5146 - val_accuracy: 0.8289\n",
      "Epoch 215/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4193 - accuracy: 0.8560 - val_loss: 0.5298 - val_accuracy: 0.8068\n",
      "Epoch 216/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3603 - accuracy: 0.8688 - val_loss: 0.5174 - val_accuracy: 0.8191\n",
      "Epoch 217/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4067 - accuracy: 0.8591 - val_loss: 0.5696 - val_accuracy: 0.8020\n",
      "Epoch 218/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3520 - accuracy: 0.8737 - val_loss: 0.5623 - val_accuracy: 0.8044\n",
      "Epoch 219/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4833 - accuracy: 0.8578 - val_loss: 0.5998 - val_accuracy: 0.7995\n",
      "Epoch 220/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3890 - accuracy: 0.8676 - val_loss: 0.5223 - val_accuracy: 0.8264\n",
      "Epoch 221/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3852 - accuracy: 0.8737 - val_loss: 0.5333 - val_accuracy: 0.8215\n",
      "Epoch 222/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3674 - accuracy: 0.8761 - val_loss: 0.5425 - val_accuracy: 0.8044\n",
      "Epoch 223/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3889 - accuracy: 0.8725 - val_loss: 0.5022 - val_accuracy: 0.8240\n",
      "Epoch 224/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3636 - accuracy: 0.8841 - val_loss: 0.4955 - val_accuracy: 0.8215\n",
      "Epoch 225/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3933 - accuracy: 0.8694 - val_loss: 0.5436 - val_accuracy: 0.8313\n",
      "Epoch 226/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3977 - accuracy: 0.8810 - val_loss: 0.5535 - val_accuracy: 0.8044\n",
      "Epoch 227/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4113 - accuracy: 0.8694 - val_loss: 0.4930 - val_accuracy: 0.8313\n",
      "Epoch 228/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3884 - accuracy: 0.8761 - val_loss: 0.5828 - val_accuracy: 0.8044\n",
      "Epoch 229/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.8627 - val_loss: 0.5848 - val_accuracy: 0.7897\n",
      "Epoch 230/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4141 - accuracy: 0.8615 - val_loss: 0.5225 - val_accuracy: 0.8215\n",
      "Epoch 231/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4020 - accuracy: 0.8621 - val_loss: 0.5028 - val_accuracy: 0.8435\n",
      "Epoch 232/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4147 - accuracy: 0.8609 - val_loss: 0.5770 - val_accuracy: 0.8093\n",
      "Epoch 233/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3668 - accuracy: 0.8774 - val_loss: 0.5131 - val_accuracy: 0.8264\n",
      "Epoch 234/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3909 - accuracy: 0.8700 - val_loss: 0.5192 - val_accuracy: 0.8166\n",
      "Epoch 235/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4006 - accuracy: 0.8774 - val_loss: 0.5230 - val_accuracy: 0.8142\n",
      "Epoch 236/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.8530 - val_loss: 0.5603 - val_accuracy: 0.8215\n",
      "Epoch 237/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3965 - accuracy: 0.8707 - val_loss: 0.5476 - val_accuracy: 0.8117\n",
      "Epoch 238/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4113 - accuracy: 0.8578 - val_loss: 0.4896 - val_accuracy: 0.8362\n",
      "Epoch 239/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3934 - accuracy: 0.8676 - val_loss: 0.4752 - val_accuracy: 0.8509\n",
      "Epoch 240/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3942 - accuracy: 0.8700 - val_loss: 0.4907 - val_accuracy: 0.8362\n",
      "Epoch 241/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3870 - accuracy: 0.8664 - val_loss: 0.5425 - val_accuracy: 0.8264\n",
      "Epoch 242/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4455 - accuracy: 0.8627 - val_loss: 0.5688 - val_accuracy: 0.7848\n",
      "Epoch 243/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4186 - accuracy: 0.8603 - val_loss: 0.5762 - val_accuracy: 0.8191\n",
      "Epoch 244/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3964 - accuracy: 0.8707 - val_loss: 0.5164 - val_accuracy: 0.8142\n",
      "Epoch 245/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8542 - val_loss: 0.5644 - val_accuracy: 0.8166\n",
      "Epoch 246/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4339 - accuracy: 0.8664 - val_loss: 0.4874 - val_accuracy: 0.8240\n",
      "Epoch 247/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4035 - accuracy: 0.8713 - val_loss: 0.5306 - val_accuracy: 0.8240\n",
      "Epoch 248/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4154 - accuracy: 0.8682 - val_loss: 0.5336 - val_accuracy: 0.8386\n",
      "Epoch 249/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3634 - accuracy: 0.8810 - val_loss: 0.6781 - val_accuracy: 0.7922\n",
      "Epoch 250/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4169 - accuracy: 0.8719 - val_loss: 0.4857 - val_accuracy: 0.8337\n",
      "Epoch 251/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3764 - accuracy: 0.8786 - val_loss: 0.5545 - val_accuracy: 0.8044\n",
      "Epoch 252/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8615 - val_loss: 0.4913 - val_accuracy: 0.8191\n",
      "Epoch 253/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3791 - accuracy: 0.8731 - val_loss: 0.5394 - val_accuracy: 0.8142\n",
      "Epoch 254/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3943 - accuracy: 0.8646 - val_loss: 0.5644 - val_accuracy: 0.8044\n",
      "Epoch 255/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3710 - accuracy: 0.8761 - val_loss: 0.5113 - val_accuracy: 0.8191\n",
      "Epoch 256/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4139 - accuracy: 0.8609 - val_loss: 0.5374 - val_accuracy: 0.8117\n",
      "Epoch 257/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3784 - accuracy: 0.8816 - val_loss: 0.5508 - val_accuracy: 0.8117\n",
      "Epoch 258/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4199 - accuracy: 0.8670 - val_loss: 0.5770 - val_accuracy: 0.8191\n",
      "Epoch 259/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3865 - accuracy: 0.8755 - val_loss: 0.5503 - val_accuracy: 0.8191\n",
      "Epoch 260/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4018 - accuracy: 0.8664 - val_loss: 0.6120 - val_accuracy: 0.7897\n",
      "Epoch 261/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4450 - accuracy: 0.8621 - val_loss: 0.5501 - val_accuracy: 0.8020\n",
      "Epoch 262/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4043 - accuracy: 0.8719 - val_loss: 0.5857 - val_accuracy: 0.7995\n",
      "Epoch 263/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3824 - accuracy: 0.8670 - val_loss: 0.5549 - val_accuracy: 0.8289\n",
      "Epoch 264/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3600 - accuracy: 0.8877 - val_loss: 0.5273 - val_accuracy: 0.8264\n",
      "Epoch 265/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4464 - accuracy: 0.8450 - val_loss: 0.6143 - val_accuracy: 0.7946\n",
      "Epoch 266/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4097 - accuracy: 0.8658 - val_loss: 0.5337 - val_accuracy: 0.8337\n",
      "Epoch 267/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3862 - accuracy: 0.8713 - val_loss: 0.4634 - val_accuracy: 0.8215\n",
      "Epoch 268/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4025 - accuracy: 0.8646 - val_loss: 0.5662 - val_accuracy: 0.8068\n",
      "Epoch 269/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4007 - accuracy: 0.8646 - val_loss: 0.4637 - val_accuracy: 0.8484\n",
      "Epoch 270/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3503 - accuracy: 0.8829 - val_loss: 0.5047 - val_accuracy: 0.8264\n",
      "Epoch 271/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3707 - accuracy: 0.8700 - val_loss: 0.5139 - val_accuracy: 0.8264\n",
      "Epoch 272/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4107 - accuracy: 0.8639 - val_loss: 0.5597 - val_accuracy: 0.8166\n",
      "Epoch 273/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4145 - accuracy: 0.8749 - val_loss: 0.5764 - val_accuracy: 0.7848\n",
      "Epoch 274/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3805 - accuracy: 0.8829 - val_loss: 0.5532 - val_accuracy: 0.8313\n",
      "Epoch 275/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3669 - accuracy: 0.8804 - val_loss: 0.5384 - val_accuracy: 0.8142\n",
      "Epoch 276/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4116 - accuracy: 0.8652 - val_loss: 0.5956 - val_accuracy: 0.7922\n",
      "Epoch 277/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3968 - accuracy: 0.8670 - val_loss: 0.6118 - val_accuracy: 0.7922\n",
      "Epoch 278/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.6199 - accuracy: 0.8682 - val_loss: 0.5143 - val_accuracy: 0.8264\n",
      "Epoch 279/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3812 - accuracy: 0.8768 - val_loss: 0.5359 - val_accuracy: 0.8289\n",
      "Epoch 280/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3969 - accuracy: 0.8621 - val_loss: 0.5294 - val_accuracy: 0.7897\n",
      "Epoch 281/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3997 - accuracy: 0.8670 - val_loss: 0.6070 - val_accuracy: 0.7946\n",
      "Epoch 282/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3952 - accuracy: 0.8658 - val_loss: 0.5258 - val_accuracy: 0.8264\n",
      "Epoch 283/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.8761 - val_loss: 0.5643 - val_accuracy: 0.8166\n",
      "Epoch 284/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4296 - accuracy: 0.8664 - val_loss: 0.5287 - val_accuracy: 0.8191\n",
      "Epoch 285/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3916 - accuracy: 0.8786 - val_loss: 0.5475 - val_accuracy: 0.8166\n",
      "Epoch 286/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3647 - accuracy: 0.8792 - val_loss: 0.4901 - val_accuracy: 0.8313\n",
      "Epoch 287/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4456 - accuracy: 0.8670 - val_loss: 0.5311 - val_accuracy: 0.8068\n",
      "Epoch 288/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3978 - accuracy: 0.8578 - val_loss: 0.5157 - val_accuracy: 0.8142\n",
      "Epoch 289/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3975 - accuracy: 0.8652 - val_loss: 0.5182 - val_accuracy: 0.8117\n",
      "Epoch 290/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4134 - accuracy: 0.8725 - val_loss: 0.5225 - val_accuracy: 0.8093\n",
      "Epoch 291/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.8682 - val_loss: 0.4745 - val_accuracy: 0.8557\n",
      "Epoch 292/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4207 - accuracy: 0.8676 - val_loss: 0.5938 - val_accuracy: 0.8117\n",
      "Epoch 293/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4123 - accuracy: 0.8774 - val_loss: 0.5304 - val_accuracy: 0.8142\n",
      "Epoch 294/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4125 - accuracy: 0.8670 - val_loss: 0.5133 - val_accuracy: 0.8386\n",
      "Epoch 295/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4100 - accuracy: 0.8621 - val_loss: 0.4925 - val_accuracy: 0.8337\n",
      "Epoch 296/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4176 - accuracy: 0.8548 - val_loss: 0.5510 - val_accuracy: 0.8215\n",
      "Epoch 297/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3914 - accuracy: 0.8664 - val_loss: 0.5867 - val_accuracy: 0.8093\n",
      "Epoch 298/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3642 - accuracy: 0.8926 - val_loss: 0.6593 - val_accuracy: 0.7628\n",
      "Epoch 299/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3801 - accuracy: 0.8792 - val_loss: 0.5588 - val_accuracy: 0.8142\n",
      "Epoch 300/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4119 - accuracy: 0.8658 - val_loss: 0.4988 - val_accuracy: 0.8411\n",
      "Epoch 301/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4154 - accuracy: 0.8664 - val_loss: 0.5116 - val_accuracy: 0.8240\n",
      "Epoch 302/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3973 - accuracy: 0.8700 - val_loss: 0.5301 - val_accuracy: 0.8289\n",
      "Epoch 303/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3991 - accuracy: 0.8664 - val_loss: 0.5271 - val_accuracy: 0.8117\n",
      "Epoch 304/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4781 - accuracy: 0.8462 - val_loss: 0.4636 - val_accuracy: 0.8362\n",
      "Epoch 305/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3700 - accuracy: 0.8768 - val_loss: 0.5290 - val_accuracy: 0.8117\n",
      "Epoch 306/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4048 - accuracy: 0.8835 - val_loss: 0.5688 - val_accuracy: 0.7897\n",
      "Epoch 307/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4079 - accuracy: 0.8713 - val_loss: 0.6162 - val_accuracy: 0.7946\n",
      "Epoch 308/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3798 - accuracy: 0.8676 - val_loss: 0.5532 - val_accuracy: 0.8289\n",
      "Epoch 309/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3995 - accuracy: 0.8725 - val_loss: 0.5674 - val_accuracy: 0.8044\n",
      "Epoch 310/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4107 - accuracy: 0.8664 - val_loss: 0.5223 - val_accuracy: 0.8264\n",
      "Epoch 311/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8639 - val_loss: 0.5561 - val_accuracy: 0.8068\n",
      "Epoch 312/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8755 - val_loss: 0.5552 - val_accuracy: 0.8142\n",
      "Epoch 313/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3799 - accuracy: 0.8816 - val_loss: 0.5339 - val_accuracy: 0.8117\n",
      "Epoch 314/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4033 - accuracy: 0.8694 - val_loss: 0.6085 - val_accuracy: 0.7971\n",
      "Epoch 315/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8707 - val_loss: 0.5128 - val_accuracy: 0.8289\n",
      "Epoch 316/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3557 - accuracy: 0.8798 - val_loss: 0.5995 - val_accuracy: 0.8166\n",
      "Epoch 317/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3503 - accuracy: 0.8853 - val_loss: 0.4887 - val_accuracy: 0.8411\n",
      "Epoch 318/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3735 - accuracy: 0.8816 - val_loss: 0.5509 - val_accuracy: 0.7995\n",
      "Epoch 319/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4525 - accuracy: 0.8633 - val_loss: 0.5124 - val_accuracy: 0.8240\n",
      "Epoch 320/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3820 - accuracy: 0.8731 - val_loss: 0.4813 - val_accuracy: 0.8386\n",
      "Epoch 321/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4117 - accuracy: 0.8737 - val_loss: 0.6086 - val_accuracy: 0.7971\n",
      "Epoch 322/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4476 - accuracy: 0.8560 - val_loss: 0.5223 - val_accuracy: 0.8117\n",
      "Epoch 323/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3924 - accuracy: 0.8835 - val_loss: 0.4942 - val_accuracy: 0.8215\n",
      "Epoch 324/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4229 - accuracy: 0.8627 - val_loss: 0.4904 - val_accuracy: 0.8191\n",
      "Epoch 325/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3797 - accuracy: 0.8707 - val_loss: 0.5592 - val_accuracy: 0.7922\n",
      "Epoch 326/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4230 - accuracy: 0.8652 - val_loss: 0.5559 - val_accuracy: 0.8117\n",
      "Epoch 327/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3772 - accuracy: 0.8743 - val_loss: 0.5608 - val_accuracy: 0.8313\n",
      "Epoch 328/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3532 - accuracy: 0.8780 - val_loss: 0.5811 - val_accuracy: 0.8117\n",
      "Epoch 329/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4242 - accuracy: 0.8658 - val_loss: 0.5524 - val_accuracy: 0.8264\n",
      "Epoch 330/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4124 - accuracy: 0.8609 - val_loss: 0.5589 - val_accuracy: 0.8166\n",
      "Epoch 331/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3907 - accuracy: 0.8810 - val_loss: 0.5174 - val_accuracy: 0.8289\n",
      "Epoch 332/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4142 - accuracy: 0.8707 - val_loss: 0.5656 - val_accuracy: 0.8093\n",
      "Epoch 333/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8615 - val_loss: 0.5171 - val_accuracy: 0.8215\n",
      "Epoch 334/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3568 - accuracy: 0.8829 - val_loss: 0.5158 - val_accuracy: 0.8337\n",
      "Epoch 335/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4232 - accuracy: 0.8652 - val_loss: 0.5611 - val_accuracy: 0.8240\n",
      "Epoch 336/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4054 - accuracy: 0.8627 - val_loss: 0.6174 - val_accuracy: 0.8068\n",
      "Epoch 337/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4325 - accuracy: 0.8597 - val_loss: 0.6113 - val_accuracy: 0.7922\n",
      "Epoch 338/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4096 - accuracy: 0.8603 - val_loss: 0.5047 - val_accuracy: 0.8435\n",
      "Epoch 339/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4375 - accuracy: 0.8603 - val_loss: 0.5310 - val_accuracy: 0.8191\n",
      "Epoch 340/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3499 - accuracy: 0.8896 - val_loss: 0.6084 - val_accuracy: 0.7946\n",
      "Epoch 341/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4198 - accuracy: 0.8707 - val_loss: 0.5778 - val_accuracy: 0.8068\n",
      "Epoch 342/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4303 - accuracy: 0.8578 - val_loss: 0.6051 - val_accuracy: 0.7971\n",
      "Epoch 343/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3827 - accuracy: 0.8707 - val_loss: 0.5110 - val_accuracy: 0.8362\n",
      "Epoch 344/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4247 - accuracy: 0.8725 - val_loss: 0.5450 - val_accuracy: 0.8509\n",
      "Epoch 345/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4189 - accuracy: 0.8615 - val_loss: 0.6462 - val_accuracy: 0.7824\n",
      "Epoch 346/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8505 - val_loss: 0.5383 - val_accuracy: 0.8215\n",
      "Epoch 347/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4343 - accuracy: 0.8597 - val_loss: 0.5575 - val_accuracy: 0.8313\n",
      "Epoch 348/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3695 - accuracy: 0.8859 - val_loss: 0.5828 - val_accuracy: 0.8117\n",
      "Epoch 349/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4582 - accuracy: 0.8646 - val_loss: 0.5234 - val_accuracy: 0.8068\n",
      "Epoch 350/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4064 - accuracy: 0.8670 - val_loss: 0.5825 - val_accuracy: 0.7922\n",
      "Epoch 351/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4055 - accuracy: 0.8578 - val_loss: 0.6175 - val_accuracy: 0.7971\n",
      "Epoch 352/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3933 - accuracy: 0.8719 - val_loss: 0.5002 - val_accuracy: 0.8386\n",
      "Epoch 353/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3849 - accuracy: 0.8749 - val_loss: 0.5178 - val_accuracy: 0.8166\n",
      "Epoch 354/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3877 - accuracy: 0.8719 - val_loss: 0.6327 - val_accuracy: 0.7873\n",
      "Epoch 355/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3863 - accuracy: 0.8755 - val_loss: 0.6520 - val_accuracy: 0.7922\n",
      "Epoch 356/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3706 - accuracy: 0.8749 - val_loss: 0.5714 - val_accuracy: 0.8215\n",
      "Epoch 357/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3927 - accuracy: 0.8719 - val_loss: 0.5552 - val_accuracy: 0.8093\n",
      "Epoch 358/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3669 - accuracy: 0.8780 - val_loss: 0.5143 - val_accuracy: 0.8240\n",
      "Epoch 359/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4126 - accuracy: 0.8646 - val_loss: 0.4966 - val_accuracy: 0.8117\n",
      "Epoch 360/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3685 - accuracy: 0.8731 - val_loss: 0.5587 - val_accuracy: 0.8020\n",
      "Epoch 361/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3789 - accuracy: 0.8780 - val_loss: 0.6207 - val_accuracy: 0.8240\n",
      "Epoch 362/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3755 - accuracy: 0.8871 - val_loss: 0.5785 - val_accuracy: 0.7946\n",
      "Epoch 363/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3609 - accuracy: 0.8859 - val_loss: 0.4993 - val_accuracy: 0.8289\n",
      "Epoch 364/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4121 - accuracy: 0.8627 - val_loss: 0.5686 - val_accuracy: 0.7946\n",
      "Epoch 365/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3954 - accuracy: 0.8749 - val_loss: 0.5231 - val_accuracy: 0.8117\n",
      "Epoch 366/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4206 - accuracy: 0.8688 - val_loss: 0.5832 - val_accuracy: 0.8142\n",
      "Epoch 367/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3927 - accuracy: 0.8804 - val_loss: 0.6165 - val_accuracy: 0.7971\n",
      "Epoch 368/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4008 - accuracy: 0.8707 - val_loss: 0.5206 - val_accuracy: 0.8313\n",
      "Epoch 369/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3978 - accuracy: 0.8786 - val_loss: 0.6458 - val_accuracy: 0.7800\n",
      "Epoch 370/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3569 - accuracy: 0.8829 - val_loss: 0.5768 - val_accuracy: 0.8337\n",
      "Epoch 371/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3883 - accuracy: 0.8700 - val_loss: 0.5259 - val_accuracy: 0.8289\n",
      "Epoch 372/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3981 - accuracy: 0.8688 - val_loss: 0.5356 - val_accuracy: 0.8142\n",
      "Epoch 373/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4153 - accuracy: 0.8597 - val_loss: 0.5168 - val_accuracy: 0.8117\n",
      "Epoch 374/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3813 - accuracy: 0.8829 - val_loss: 0.5304 - val_accuracy: 0.7971\n",
      "Epoch 375/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4014 - accuracy: 0.8676 - val_loss: 0.5167 - val_accuracy: 0.8289\n",
      "Epoch 376/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4068 - accuracy: 0.8688 - val_loss: 0.4943 - val_accuracy: 0.8362\n",
      "Epoch 377/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4170 - accuracy: 0.8707 - val_loss: 0.6039 - val_accuracy: 0.8117\n",
      "Epoch 378/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3978 - accuracy: 0.8768 - val_loss: 0.4937 - val_accuracy: 0.8166\n",
      "Epoch 379/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4261 - accuracy: 0.8725 - val_loss: 0.5455 - val_accuracy: 0.8093\n",
      "Epoch 380/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3916 - accuracy: 0.8755 - val_loss: 0.5529 - val_accuracy: 0.8142\n",
      "Epoch 381/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4138 - accuracy: 0.8694 - val_loss: 0.5606 - val_accuracy: 0.8044\n",
      "Epoch 382/10000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.8646 - val_loss: 0.5104 - val_accuracy: 0.8264\n",
      "Epoch 383/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3811 - accuracy: 0.8768 - val_loss: 0.5085 - val_accuracy: 0.8289\n",
      "Epoch 384/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4069 - accuracy: 0.8670 - val_loss: 0.6116 - val_accuracy: 0.7873\n",
      "Epoch 385/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3717 - accuracy: 0.8816 - val_loss: 0.5764 - val_accuracy: 0.7946\n",
      "Epoch 386/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3550 - accuracy: 0.8822 - val_loss: 0.5496 - val_accuracy: 0.8264\n",
      "Epoch 387/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4316 - accuracy: 0.8597 - val_loss: 0.5218 - val_accuracy: 0.8264\n",
      "Epoch 388/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3866 - accuracy: 0.8755 - val_loss: 0.5389 - val_accuracy: 0.8020\n",
      "Epoch 389/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3994 - accuracy: 0.8804 - val_loss: 0.5916 - val_accuracy: 0.8044\n",
      "Epoch 390/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3765 - accuracy: 0.8755 - val_loss: 0.5499 - val_accuracy: 0.8215\n",
      "Epoch 391/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3975 - accuracy: 0.8707 - val_loss: 0.5516 - val_accuracy: 0.8117\n",
      "Epoch 392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 0s 9ms/step - loss: 0.3645 - accuracy: 0.8829 - val_loss: 0.5052 - val_accuracy: 0.8362\n",
      "Epoch 393/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3886 - accuracy: 0.8743 - val_loss: 0.5456 - val_accuracy: 0.8240\n",
      "Epoch 394/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4464 - accuracy: 0.8639 - val_loss: 0.4826 - val_accuracy: 0.8460\n",
      "Epoch 395/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3989 - accuracy: 0.8731 - val_loss: 0.6078 - val_accuracy: 0.8289\n",
      "Epoch 396/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3981 - accuracy: 0.8646 - val_loss: 0.5521 - val_accuracy: 0.8166\n",
      "Epoch 397/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4244 - accuracy: 0.8615 - val_loss: 0.5693 - val_accuracy: 0.8166\n",
      "Epoch 398/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3857 - accuracy: 0.8798 - val_loss: 0.5617 - val_accuracy: 0.8068\n",
      "Epoch 399/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4313 - accuracy: 0.8670 - val_loss: 0.5116 - val_accuracy: 0.8191\n",
      "Epoch 400/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3725 - accuracy: 0.8731 - val_loss: 0.5550 - val_accuracy: 0.8264\n",
      "Epoch 401/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3951 - accuracy: 0.8743 - val_loss: 0.5596 - val_accuracy: 0.7971\n",
      "Epoch 402/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3914 - accuracy: 0.8707 - val_loss: 0.5543 - val_accuracy: 0.8068\n",
      "Epoch 403/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4140 - accuracy: 0.8664 - val_loss: 0.5814 - val_accuracy: 0.8044\n",
      "Epoch 404/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4204 - accuracy: 0.8682 - val_loss: 0.5345 - val_accuracy: 0.8264\n",
      "Epoch 405/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4528 - accuracy: 0.8542 - val_loss: 0.5147 - val_accuracy: 0.8166\n",
      "Epoch 406/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3757 - accuracy: 0.8798 - val_loss: 0.5293 - val_accuracy: 0.8191\n",
      "Epoch 407/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3879 - accuracy: 0.8700 - val_loss: 0.5270 - val_accuracy: 0.8289\n",
      "Epoch 408/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4105 - accuracy: 0.8713 - val_loss: 0.5966 - val_accuracy: 0.8044\n",
      "Epoch 409/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3847 - accuracy: 0.8847 - val_loss: 0.5646 - val_accuracy: 0.8166\n",
      "Epoch 410/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4137 - accuracy: 0.8591 - val_loss: 0.5975 - val_accuracy: 0.8044\n",
      "Epoch 411/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3954 - accuracy: 0.8682 - val_loss: 0.5848 - val_accuracy: 0.8117\n",
      "Epoch 412/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3984 - accuracy: 0.8652 - val_loss: 0.5384 - val_accuracy: 0.8240\n",
      "Epoch 413/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4492 - accuracy: 0.8713 - val_loss: 0.4675 - val_accuracy: 0.8509\n",
      "Epoch 414/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3881 - accuracy: 0.8670 - val_loss: 0.5664 - val_accuracy: 0.8191\n",
      "Epoch 415/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3931 - accuracy: 0.8847 - val_loss: 0.4762 - val_accuracy: 0.8411\n",
      "Epoch 416/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3489 - accuracy: 0.8816 - val_loss: 0.5740 - val_accuracy: 0.8289\n",
      "Epoch 417/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4052 - accuracy: 0.8792 - val_loss: 0.5286 - val_accuracy: 0.8117\n",
      "Epoch 418/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3644 - accuracy: 0.8786 - val_loss: 0.5914 - val_accuracy: 0.7971\n",
      "Epoch 419/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4068 - accuracy: 0.8658 - val_loss: 0.5626 - val_accuracy: 0.8093\n",
      "Epoch 420/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3910 - accuracy: 0.8786 - val_loss: 0.5942 - val_accuracy: 0.7873\n",
      "Epoch 421/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8682 - val_loss: 0.5333 - val_accuracy: 0.8142\n",
      "Epoch 422/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4593 - accuracy: 0.8682 - val_loss: 0.5464 - val_accuracy: 0.8191\n",
      "Epoch 423/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4130 - accuracy: 0.8658 - val_loss: 0.5752 - val_accuracy: 0.7971\n",
      "Epoch 424/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4133 - accuracy: 0.8652 - val_loss: 0.5698 - val_accuracy: 0.8068\n",
      "Epoch 425/10000\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.4521 - accuracy: 0.8566 - val_loss: 0.6124 - val_accuracy: 0.8068\n",
      "Epoch 426/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4112 - accuracy: 0.8755 - val_loss: 0.5954 - val_accuracy: 0.7946\n",
      "Epoch 427/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3722 - accuracy: 0.8737 - val_loss: 0.6014 - val_accuracy: 0.8166\n",
      "Epoch 428/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3916 - accuracy: 0.8755 - val_loss: 0.5115 - val_accuracy: 0.8264\n",
      "Epoch 429/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4102 - accuracy: 0.8682 - val_loss: 0.5686 - val_accuracy: 0.8093\n",
      "Epoch 430/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3535 - accuracy: 0.8829 - val_loss: 0.5831 - val_accuracy: 0.8240\n",
      "Epoch 431/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4083 - accuracy: 0.8652 - val_loss: 0.5892 - val_accuracy: 0.8093\n",
      "Epoch 432/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4885 - accuracy: 0.8658 - val_loss: 0.5555 - val_accuracy: 0.7971\n",
      "Epoch 433/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3660 - accuracy: 0.8780 - val_loss: 0.5379 - val_accuracy: 0.8215\n",
      "Epoch 434/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3964 - accuracy: 0.8743 - val_loss: 0.5313 - val_accuracy: 0.8166\n",
      "Epoch 435/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3943 - accuracy: 0.8658 - val_loss: 0.6021 - val_accuracy: 0.8044\n",
      "Epoch 436/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4170 - accuracy: 0.8652 - val_loss: 0.5215 - val_accuracy: 0.8362\n",
      "Epoch 437/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3875 - accuracy: 0.8694 - val_loss: 0.5043 - val_accuracy: 0.8215\n",
      "Epoch 438/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3902 - accuracy: 0.8737 - val_loss: 0.5708 - val_accuracy: 0.7995\n",
      "Epoch 439/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4015 - accuracy: 0.8688 - val_loss: 0.5944 - val_accuracy: 0.7848\n",
      "Epoch 440/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3872 - accuracy: 0.8719 - val_loss: 0.5787 - val_accuracy: 0.7848\n",
      "Epoch 441/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4388 - accuracy: 0.8615 - val_loss: 0.5009 - val_accuracy: 0.8044\n",
      "Epoch 442/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3767 - accuracy: 0.8835 - val_loss: 0.5552 - val_accuracy: 0.8068\n",
      "Epoch 443/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3666 - accuracy: 0.8719 - val_loss: 0.5711 - val_accuracy: 0.8215\n",
      "Epoch 444/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4024 - accuracy: 0.8694 - val_loss: 0.5523 - val_accuracy: 0.8166\n",
      "Epoch 445/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3957 - accuracy: 0.8780 - val_loss: 0.4765 - val_accuracy: 0.8435\n",
      "Epoch 446/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5272 - accuracy: 0.8499 - val_loss: 0.5430 - val_accuracy: 0.8166\n",
      "Epoch 447/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4143 - accuracy: 0.8700 - val_loss: 0.5155 - val_accuracy: 0.8289\n",
      "Epoch 448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3975 - accuracy: 0.8700 - val_loss: 0.5375 - val_accuracy: 0.8142\n",
      "Epoch 449/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3932 - accuracy: 0.8804 - val_loss: 0.5487 - val_accuracy: 0.8166\n",
      "Epoch 450/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3718 - accuracy: 0.8810 - val_loss: 0.5073 - val_accuracy: 0.8264\n",
      "Epoch 451/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4337 - accuracy: 0.8597 - val_loss: 0.5703 - val_accuracy: 0.8142\n",
      "Epoch 452/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4216 - accuracy: 0.8591 - val_loss: 0.5763 - val_accuracy: 0.7995\n",
      "Epoch 453/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3601 - accuracy: 0.8743 - val_loss: 0.5742 - val_accuracy: 0.8240\n",
      "Epoch 454/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3874 - accuracy: 0.8688 - val_loss: 0.5351 - val_accuracy: 0.8093\n",
      "Epoch 455/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3979 - accuracy: 0.8713 - val_loss: 0.4985 - val_accuracy: 0.8264\n",
      "Epoch 456/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4149 - accuracy: 0.8609 - val_loss: 0.5086 - val_accuracy: 0.8215\n",
      "Epoch 457/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3784 - accuracy: 0.8713 - val_loss: 0.5481 - val_accuracy: 0.8215\n",
      "Epoch 458/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4099 - accuracy: 0.8768 - val_loss: 0.5191 - val_accuracy: 0.8117\n",
      "Epoch 459/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3539 - accuracy: 0.8719 - val_loss: 0.5385 - val_accuracy: 0.8093\n",
      "Epoch 460/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4156 - accuracy: 0.8658 - val_loss: 0.6200 - val_accuracy: 0.7995\n",
      "Epoch 461/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4315 - accuracy: 0.8639 - val_loss: 0.4986 - val_accuracy: 0.8460\n",
      "Epoch 462/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4011 - accuracy: 0.8664 - val_loss: 0.4941 - val_accuracy: 0.8362\n",
      "Epoch 463/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3679 - accuracy: 0.8688 - val_loss: 0.5644 - val_accuracy: 0.8117\n",
      "Epoch 464/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3981 - accuracy: 0.8700 - val_loss: 0.5240 - val_accuracy: 0.8191\n",
      "Epoch 465/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.8688 - val_loss: 0.5592 - val_accuracy: 0.8240\n",
      "Epoch 466/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4017 - accuracy: 0.8633 - val_loss: 0.5513 - val_accuracy: 0.8313\n",
      "Epoch 467/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4111 - accuracy: 0.8639 - val_loss: 0.5900 - val_accuracy: 0.8044\n",
      "Epoch 468/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4178 - accuracy: 0.8700 - val_loss: 0.5103 - val_accuracy: 0.8215\n",
      "Epoch 469/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4094 - accuracy: 0.8798 - val_loss: 0.6130 - val_accuracy: 0.7922\n",
      "Epoch 470/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4089 - accuracy: 0.8725 - val_loss: 0.5454 - val_accuracy: 0.8191\n",
      "Epoch 471/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3577 - accuracy: 0.8822 - val_loss: 0.4992 - val_accuracy: 0.8044\n",
      "Epoch 472/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3679 - accuracy: 0.8804 - val_loss: 0.4657 - val_accuracy: 0.8435\n",
      "Epoch 473/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4191 - accuracy: 0.8603 - val_loss: 0.4826 - val_accuracy: 0.8386\n",
      "Epoch 474/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.8507 - accuracy: 0.8652 - val_loss: 0.5464 - val_accuracy: 0.7971\n",
      "Epoch 475/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3710 - accuracy: 0.8761 - val_loss: 0.4966 - val_accuracy: 0.8117\n",
      "Epoch 476/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3992 - accuracy: 0.8707 - val_loss: 0.5916 - val_accuracy: 0.8240\n",
      "Epoch 477/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3736 - accuracy: 0.8847 - val_loss: 0.5569 - val_accuracy: 0.8142\n",
      "Epoch 478/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3756 - accuracy: 0.8786 - val_loss: 0.5712 - val_accuracy: 0.8240\n",
      "Epoch 479/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4259 - accuracy: 0.8682 - val_loss: 0.5840 - val_accuracy: 0.8313\n",
      "Epoch 480/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3926 - accuracy: 0.8664 - val_loss: 0.5406 - val_accuracy: 0.8240\n",
      "Epoch 481/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4596 - accuracy: 0.8505 - val_loss: 0.4802 - val_accuracy: 0.8460\n",
      "Epoch 482/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4109 - accuracy: 0.8713 - val_loss: 0.5578 - val_accuracy: 0.8068\n",
      "Epoch 483/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4113 - accuracy: 0.8822 - val_loss: 0.5966 - val_accuracy: 0.7971\n",
      "Epoch 484/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3781 - accuracy: 0.8810 - val_loss: 0.6035 - val_accuracy: 0.8093\n",
      "Epoch 485/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4911 - accuracy: 0.8591 - val_loss: 0.5656 - val_accuracy: 0.8068\n",
      "Epoch 486/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3797 - accuracy: 0.8804 - val_loss: 0.5453 - val_accuracy: 0.8264\n",
      "Epoch 487/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3964 - accuracy: 0.8816 - val_loss: 0.5133 - val_accuracy: 0.8093\n",
      "Epoch 488/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3991 - accuracy: 0.8780 - val_loss: 0.5436 - val_accuracy: 0.8289\n",
      "Epoch 489/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4126 - accuracy: 0.8731 - val_loss: 0.6779 - val_accuracy: 0.8044\n",
      "Epoch 490/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3837 - accuracy: 0.8774 - val_loss: 0.5513 - val_accuracy: 0.7995\n",
      "Epoch 491/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4113 - accuracy: 0.8664 - val_loss: 0.5855 - val_accuracy: 0.8044\n",
      "Epoch 492/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4174 - accuracy: 0.8670 - val_loss: 0.5445 - val_accuracy: 0.8142\n",
      "Epoch 493/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4050 - accuracy: 0.8719 - val_loss: 0.4989 - val_accuracy: 0.8166\n",
      "Epoch 494/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4209 - accuracy: 0.8725 - val_loss: 0.5126 - val_accuracy: 0.8191\n",
      "Epoch 495/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.5838 - accuracy: 0.8542 - val_loss: 0.5256 - val_accuracy: 0.8166\n",
      "Epoch 496/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3840 - accuracy: 0.8780 - val_loss: 0.7037 - val_accuracy: 0.7873\n",
      "Epoch 497/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3672 - accuracy: 0.8737 - val_loss: 0.5002 - val_accuracy: 0.8191\n",
      "Epoch 498/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4351 - accuracy: 0.8517 - val_loss: 0.6466 - val_accuracy: 0.7897\n",
      "Epoch 499/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4873 - accuracy: 0.8682 - val_loss: 0.4828 - val_accuracy: 0.8411\n",
      "Epoch 500/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3808 - accuracy: 0.8731 - val_loss: 0.6595 - val_accuracy: 0.7800\n",
      "Epoch 501/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3865 - accuracy: 0.8694 - val_loss: 0.5283 - val_accuracy: 0.8215\n",
      "Epoch 502/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4047 - accuracy: 0.8700 - val_loss: 0.5857 - val_accuracy: 0.8044\n",
      "Epoch 503/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8682 - val_loss: 0.5842 - val_accuracy: 0.8068\n",
      "Epoch 504/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4082 - accuracy: 0.8688 - val_loss: 0.4927 - val_accuracy: 0.8460\n",
      "Epoch 505/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3963 - accuracy: 0.8804 - val_loss: 0.4880 - val_accuracy: 0.8313\n",
      "Epoch 506/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4285 - accuracy: 0.8707 - val_loss: 0.5886 - val_accuracy: 0.7922\n",
      "Epoch 507/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4155 - accuracy: 0.8627 - val_loss: 0.5278 - val_accuracy: 0.8191\n",
      "Epoch 508/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4661 - accuracy: 0.8481 - val_loss: 0.5157 - val_accuracy: 0.8240\n",
      "Epoch 509/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4148 - accuracy: 0.8700 - val_loss: 0.5578 - val_accuracy: 0.8068\n",
      "Epoch 510/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3970 - accuracy: 0.8816 - val_loss: 0.5944 - val_accuracy: 0.8240\n",
      "Epoch 511/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4246 - accuracy: 0.8603 - val_loss: 0.5640 - val_accuracy: 0.8093\n",
      "Epoch 512/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3673 - accuracy: 0.8871 - val_loss: 0.5481 - val_accuracy: 0.8044\n",
      "Epoch 513/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.6579 - accuracy: 0.8737 - val_loss: 0.4751 - val_accuracy: 0.8264\n",
      "Epoch 514/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3739 - accuracy: 0.8792 - val_loss: 0.4390 - val_accuracy: 0.8484\n",
      "Epoch 515/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4376 - accuracy: 0.8658 - val_loss: 0.5261 - val_accuracy: 0.8264\n",
      "Epoch 516/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3966 - accuracy: 0.8652 - val_loss: 0.6134 - val_accuracy: 0.8117\n",
      "Epoch 517/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3931 - accuracy: 0.8737 - val_loss: 0.5737 - val_accuracy: 0.8166\n",
      "Epoch 518/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3577 - accuracy: 0.8780 - val_loss: 0.5807 - val_accuracy: 0.7873\n",
      "Epoch 519/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3821 - accuracy: 0.8737 - val_loss: 0.5995 - val_accuracy: 0.8044\n",
      "Epoch 520/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.4292 - accuracy: 0.8639 - val_loss: 0.5519 - val_accuracy: 0.8093\n",
      "Epoch 521/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4316 - accuracy: 0.8615 - val_loss: 0.5796 - val_accuracy: 0.8289\n",
      "Epoch 522/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4345 - accuracy: 0.8621 - val_loss: 0.5454 - val_accuracy: 0.8068\n",
      "Epoch 523/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.3903 - accuracy: 0.8719 - val_loss: 0.5663 - val_accuracy: 0.8362\n",
      "Epoch 524/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3637 - accuracy: 0.8853 - val_loss: 0.4707 - val_accuracy: 0.8557\n",
      "Epoch 525/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4063 - accuracy: 0.8816 - val_loss: 0.4720 - val_accuracy: 0.8289\n",
      "Epoch 526/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4142 - accuracy: 0.8694 - val_loss: 0.5653 - val_accuracy: 0.8093\n",
      "Epoch 527/10000\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 0.5092 - accuracy: 0.8768 - val_loss: 0.5182 - val_accuracy: 0.8093\n",
      "Epoch 528/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3789 - accuracy: 0.8713 - val_loss: 0.5425 - val_accuracy: 0.8362\n",
      "Epoch 529/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.4573 - accuracy: 0.8578 - val_loss: 0.4992 - val_accuracy: 0.8191\n",
      "Epoch 530/10000\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.3962 - accuracy: 0.8719 - val_loss: 0.4740 - val_accuracy: 0.8484\n",
      "Epoch 531/10000\n",
      "43/52 [=======================>......] - ETA: 0s - loss: 0.3798 - accuracy: 0.8816"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6fb2895e4318>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     validation_data = validation_generator)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1304\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=10000, batch_size=32,\n",
    "                   validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy=0.83893, Validation accuracy=0.85086\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(history.history['accuracy'],label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
