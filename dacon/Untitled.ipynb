{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('./train.csv')\n",
    "test = pd.read_csv('./test.csv')\n",
    "submission = pd.read_csv('./submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = (train[[str(i) for i in range(784)]]/255.).values.reshape(-1,28,28,1)\n",
    "y_train_full = train['digit'].values\n",
    "z_train_full = train['letter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 36,\n",
    "    zoom_range = 0.20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    validation_split=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = datagen.flow(\n",
    "    X_train_full, y_train_full,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator = datagen.flow(\n",
    "    X_train_full, y_train_full,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_train = np.array(z_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'B', 'L', ..., 'A', 'Z', 'Z'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_uppercase\n",
    "alpha_list = list(ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = to_categorical(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 26)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_list[np.argmax(z[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "train_generator2 = datagen.flow(\n",
    "    X_train_full, z,\n",
    "    batch_size=batch_size,\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator2 = datagen.flow(\n",
    "    X_train_full, z,\n",
    "    batch_size=batch_size,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\",\n",
    "                       input_shape=(28,28,1)))\n",
    "model.add(layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\",))\n",
    "model.add(layers.Conv2D(32, kernel_size=3, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "          \n",
    "model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, kernel_size=3, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(128, kernel_size=3, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(26, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = layers.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_)\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(32, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(256, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x1 = layers.Dense(26, activation = \"softmax\")(x)\n",
    "\n",
    "model1 = models.Model(inputs=input_, outputs=x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ = layers.Dense(128, activation=\"relu\")(x)\n",
    "x1_ = layers.Dense(128, activation=\"relu\")(x1)\n",
    "y = layers.Concatenate(axis=1)([x_, x1])\n",
    "output_ = layers.Dense(10, activation=\"softmax\")(y)\n",
    "#model2= models.Model(inputs=[x_, x1_], outputs=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2= models.Model(inputs=input_, outputs=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 28, 28, 32)   320         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 28, 28, 32)   9248        conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 13, 32)   9248        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 13, 13, 32)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 64)   18496       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 13, 13, 64)   36928       conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 6, 64)     36928       conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 6, 6, 64)     0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 6, 128)    73856       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 6, 6, 128)    147584      conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 2, 2, 128)    147584      conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 2, 2, 128)    0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 2, 2, 256)    295168      dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 1024)         0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 1024)         0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          131200      dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 26)           26650       dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 154)          0           dense_16[0][0]                   \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10)           1550        concatenate_4[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 934,760\n",
      "Trainable params: 934,760\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_l = layers.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_l)\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "output_l = layers.Dense(26, activation = \"softmax\")(x)\n",
    "\n",
    "base_model_l = models.Model(inputs=[input_l], outputs=[output_l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 48 steps, validate for 16 steps\n",
      "Epoch 1/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5085 - accuracy: 0.8451 - val_loss: 0.6903 - val_accuracy: 0.8105\n",
      "Epoch 2/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4899 - accuracy: 0.8626 - val_loss: 0.5883 - val_accuracy: 0.8125\n",
      "Epoch 3/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4717 - accuracy: 0.8594 - val_loss: 0.7278 - val_accuracy: 0.7793\n",
      "Epoch 4/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4843 - accuracy: 0.8457 - val_loss: 0.6798 - val_accuracy: 0.8164\n",
      "Epoch 5/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4154 - accuracy: 0.8717 - val_loss: 0.5788 - val_accuracy: 0.8418\n",
      "Epoch 6/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4736 - accuracy: 0.8600 - val_loss: 0.5888 - val_accuracy: 0.8184\n",
      "Epoch 7/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5235 - accuracy: 0.8444 - val_loss: 0.5919 - val_accuracy: 0.8047\n",
      "Epoch 8/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5010 - accuracy: 0.8431 - val_loss: 0.7339 - val_accuracy: 0.8008\n",
      "Epoch 9/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4731 - accuracy: 0.8574 - val_loss: 0.7334 - val_accuracy: 0.8086\n",
      "Epoch 10/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5616 - accuracy: 0.8346 - val_loss: 0.6054 - val_accuracy: 0.8145\n",
      "Epoch 11/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5343 - accuracy: 0.8379 - val_loss: 0.7075 - val_accuracy: 0.7891\n",
      "Epoch 12/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4856 - accuracy: 0.8613 - val_loss: 0.5786 - val_accuracy: 0.8301\n",
      "Epoch 13/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4791 - accuracy: 0.8594 - val_loss: 0.5558 - val_accuracy: 0.8242\n",
      "Epoch 14/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4662 - accuracy: 0.8607 - val_loss: 0.8143 - val_accuracy: 0.7715\n",
      "Epoch 15/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4814 - accuracy: 0.8665 - val_loss: 0.6621 - val_accuracy: 0.8203\n",
      "Epoch 16/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5548 - accuracy: 0.8385 - val_loss: 0.6718 - val_accuracy: 0.8008\n",
      "Epoch 17/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5028 - accuracy: 0.8496 - val_loss: 0.7270 - val_accuracy: 0.8008\n",
      "Epoch 18/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4499 - accuracy: 0.8607 - val_loss: 0.6472 - val_accuracy: 0.8125\n",
      "Epoch 19/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4971 - accuracy: 0.8535 - val_loss: 0.6310 - val_accuracy: 0.8340\n",
      "Epoch 20/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5136 - accuracy: 0.8379 - val_loss: 0.6676 - val_accuracy: 0.7988\n",
      "Epoch 21/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4947 - accuracy: 0.8587 - val_loss: 0.6466 - val_accuracy: 0.8301\n",
      "Epoch 22/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4808 - accuracy: 0.8561 - val_loss: 0.6601 - val_accuracy: 0.8164\n",
      "Epoch 23/200\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.4689 - accuracy: 0.8594 - val_loss: 0.8177 - val_accuracy: 0.7832\n",
      "Epoch 24/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5273 - accuracy: 0.8444 - val_loss: 0.6775 - val_accuracy: 0.8047\n",
      "Epoch 25/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5926 - accuracy: 0.8320 - val_loss: 0.7747 - val_accuracy: 0.7812\n",
      "Epoch 26/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4612 - accuracy: 0.8607 - val_loss: 0.5967 - val_accuracy: 0.8379\n",
      "Epoch 27/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5642 - accuracy: 0.8411 - val_loss: 0.6206 - val_accuracy: 0.8164\n",
      "Epoch 28/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4747 - accuracy: 0.8574 - val_loss: 0.6531 - val_accuracy: 0.7871\n",
      "Epoch 29/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5000 - accuracy: 0.8568 - val_loss: 0.5840 - val_accuracy: 0.8203\n",
      "Epoch 30/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4986 - accuracy: 0.8516 - val_loss: 0.6160 - val_accuracy: 0.8242\n",
      "Epoch 31/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5501 - accuracy: 0.8535 - val_loss: 0.5986 - val_accuracy: 0.8184\n",
      "Epoch 32/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5089 - accuracy: 0.8438 - val_loss: 0.6180 - val_accuracy: 0.7988\n",
      "Epoch 33/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5887 - accuracy: 0.8418 - val_loss: 0.7452 - val_accuracy: 0.8105\n",
      "Epoch 34/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4950 - accuracy: 0.8490 - val_loss: 0.6403 - val_accuracy: 0.8340\n",
      "Epoch 35/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.5234 - accuracy: 0.8490 - val_loss: 0.6476 - val_accuracy: 0.8066\n",
      "Epoch 36/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5674 - accuracy: 0.8366 - val_loss: 0.6763 - val_accuracy: 0.8125\n",
      "Epoch 37/200\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.5093 - accuracy: 0.8405 - val_loss: 0.5898 - val_accuracy: 0.8105\n",
      "Epoch 38/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5214 - accuracy: 0.8457 - val_loss: 0.5541 - val_accuracy: 0.8457\n",
      "Epoch 39/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5535 - accuracy: 0.8483 - val_loss: 0.5388 - val_accuracy: 0.8281\n",
      "Epoch 40/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5088 - accuracy: 0.8496 - val_loss: 0.5684 - val_accuracy: 0.8223\n",
      "Epoch 41/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5247 - accuracy: 0.8464 - val_loss: 0.6190 - val_accuracy: 0.8027\n",
      "Epoch 42/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5189 - accuracy: 0.8411 - val_loss: 0.6983 - val_accuracy: 0.7812\n",
      "Epoch 43/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.5147 - accuracy: 0.8451 - val_loss: 0.6557 - val_accuracy: 0.8184\n",
      "Epoch 44/200\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.5033 - accuracy: 0.8451 - val_loss: 0.6888 - val_accuracy: 0.7988\n",
      "Epoch 45/200\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.4450 - accuracy: 0.8633 - val_loss: 0.5768 - val_accuracy: 0.8262\n",
      "Epoch 46/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4747 - accuracy: 0.8607 - val_loss: 0.5568 - val_accuracy: 0.8301\n",
      "Epoch 47/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6079 - accuracy: 0.8444 - val_loss: 0.7279 - val_accuracy: 0.7988\n",
      "Epoch 48/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5164 - accuracy: 0.8464 - val_loss: 0.6717 - val_accuracy: 0.8125\n",
      "Epoch 49/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5281 - accuracy: 0.8392 - val_loss: 0.6695 - val_accuracy: 0.7891\n",
      "Epoch 50/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5284 - accuracy: 0.8405 - val_loss: 0.7207 - val_accuracy: 0.8145\n",
      "Epoch 51/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5504 - accuracy: 0.8327 - val_loss: 0.7144 - val_accuracy: 0.7891\n",
      "Epoch 52/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4911 - accuracy: 0.8535 - val_loss: 0.6894 - val_accuracy: 0.8203\n",
      "Epoch 53/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5372 - accuracy: 0.8568 - val_loss: 0.7451 - val_accuracy: 0.8047\n",
      "Epoch 54/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4965 - accuracy: 0.8529 - val_loss: 0.5931 - val_accuracy: 0.8105\n",
      "Epoch 55/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5214 - accuracy: 0.8464 - val_loss: 0.5496 - val_accuracy: 0.8223\n",
      "Epoch 56/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4643 - accuracy: 0.8555 - val_loss: 0.5968 - val_accuracy: 0.8242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5248 - accuracy: 0.8522 - val_loss: 0.6588 - val_accuracy: 0.8047\n",
      "Epoch 58/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4884 - accuracy: 0.8516 - val_loss: 0.5864 - val_accuracy: 0.8301\n",
      "Epoch 59/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5004 - accuracy: 0.8561 - val_loss: 0.5645 - val_accuracy: 0.8320\n",
      "Epoch 60/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5201 - accuracy: 0.8470 - val_loss: 0.6137 - val_accuracy: 0.8242\n",
      "Epoch 61/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5005 - accuracy: 0.8451 - val_loss: 0.5764 - val_accuracy: 0.8418\n",
      "Epoch 62/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5096 - accuracy: 0.8529 - val_loss: 0.7039 - val_accuracy: 0.8066\n",
      "Epoch 63/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5322 - accuracy: 0.8385 - val_loss: 0.5531 - val_accuracy: 0.8418\n",
      "Epoch 64/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5104 - accuracy: 0.8535 - val_loss: 0.6588 - val_accuracy: 0.8125\n",
      "Epoch 65/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5459 - accuracy: 0.8470 - val_loss: 0.5153 - val_accuracy: 0.8320\n",
      "Epoch 66/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5055 - accuracy: 0.8457 - val_loss: 0.7687 - val_accuracy: 0.7852\n",
      "Epoch 67/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5023 - accuracy: 0.8470 - val_loss: 0.7438 - val_accuracy: 0.7910\n",
      "Epoch 68/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5537 - accuracy: 0.8496 - val_loss: 0.7337 - val_accuracy: 0.7832\n",
      "Epoch 69/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4619 - accuracy: 0.8587 - val_loss: 0.7151 - val_accuracy: 0.7949\n",
      "Epoch 70/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5542 - accuracy: 0.8464 - val_loss: 0.7605 - val_accuracy: 0.7910\n",
      "Epoch 71/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5521 - accuracy: 0.8405 - val_loss: 0.6495 - val_accuracy: 0.8145\n",
      "Epoch 72/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5509 - accuracy: 0.8490 - val_loss: 0.6117 - val_accuracy: 0.8145\n",
      "Epoch 73/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4920 - accuracy: 0.8516 - val_loss: 0.6117 - val_accuracy: 0.8164\n",
      "Epoch 74/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5801 - accuracy: 0.8470 - val_loss: 0.7802 - val_accuracy: 0.7969\n",
      "Epoch 75/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5292 - accuracy: 0.8600 - val_loss: 0.6265 - val_accuracy: 0.8340\n",
      "Epoch 76/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5973 - accuracy: 0.8210 - val_loss: 0.6787 - val_accuracy: 0.7832\n",
      "Epoch 77/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5686 - accuracy: 0.8379 - val_loss: 0.6242 - val_accuracy: 0.8223\n",
      "Epoch 78/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5187 - accuracy: 0.8438 - val_loss: 0.7020 - val_accuracy: 0.7754\n",
      "Epoch 79/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5546 - accuracy: 0.8359 - val_loss: 0.6636 - val_accuracy: 0.8359\n",
      "Epoch 80/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5535 - accuracy: 0.8522 - val_loss: 0.6427 - val_accuracy: 0.8184\n",
      "Epoch 81/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5693 - accuracy: 0.8535 - val_loss: 0.7087 - val_accuracy: 0.8066\n",
      "Epoch 82/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5127 - accuracy: 0.8587 - val_loss: 0.6683 - val_accuracy: 0.8340\n",
      "Epoch 83/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5422 - accuracy: 0.8574 - val_loss: 0.5515 - val_accuracy: 0.8301\n",
      "Epoch 84/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5001 - accuracy: 0.8522 - val_loss: 0.6419 - val_accuracy: 0.8027\n",
      "Epoch 85/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5853 - accuracy: 0.8372 - val_loss: 0.7469 - val_accuracy: 0.7891\n",
      "Epoch 86/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5177 - accuracy: 0.8633 - val_loss: 0.6445 - val_accuracy: 0.8008\n",
      "Epoch 87/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5672 - accuracy: 0.8327 - val_loss: 0.7764 - val_accuracy: 0.7852\n",
      "Epoch 88/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5490 - accuracy: 0.8392 - val_loss: 0.6455 - val_accuracy: 0.8086\n",
      "Epoch 89/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5113 - accuracy: 0.8438 - val_loss: 0.6024 - val_accuracy: 0.8184\n",
      "Epoch 90/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5494 - accuracy: 0.8418 - val_loss: 0.6057 - val_accuracy: 0.8164\n",
      "Epoch 91/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5089 - accuracy: 0.8516 - val_loss: 0.6453 - val_accuracy: 0.8242\n",
      "Epoch 92/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5430 - accuracy: 0.8496 - val_loss: 0.8302 - val_accuracy: 0.7949\n",
      "Epoch 93/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5705 - accuracy: 0.8398 - val_loss: 0.7025 - val_accuracy: 0.7969\n",
      "Epoch 94/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5700 - accuracy: 0.8320 - val_loss: 0.6418 - val_accuracy: 0.8086\n",
      "Epoch 95/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5698 - accuracy: 0.8346 - val_loss: 0.7110 - val_accuracy: 0.7852\n",
      "Epoch 96/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5982 - accuracy: 0.8496 - val_loss: 0.6647 - val_accuracy: 0.7930\n",
      "Epoch 97/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5049 - accuracy: 0.8626 - val_loss: 0.7773 - val_accuracy: 0.7734\n",
      "Epoch 98/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5369 - accuracy: 0.8392 - val_loss: 0.7993 - val_accuracy: 0.7930\n",
      "Epoch 99/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5344 - accuracy: 0.8555 - val_loss: 0.6761 - val_accuracy: 0.8125\n",
      "Epoch 100/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6174 - accuracy: 0.8398 - val_loss: 0.6945 - val_accuracy: 0.8027\n",
      "Epoch 101/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.8072 - accuracy: 0.8424 - val_loss: 0.6868 - val_accuracy: 0.7910\n",
      "Epoch 102/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5214 - accuracy: 0.8444 - val_loss: 0.6636 - val_accuracy: 0.7988\n",
      "Epoch 103/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5341 - accuracy: 0.8366 - val_loss: 0.7139 - val_accuracy: 0.8086\n",
      "Epoch 104/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5221 - accuracy: 0.8574 - val_loss: 0.7040 - val_accuracy: 0.7832\n",
      "Epoch 105/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5620 - accuracy: 0.8405 - val_loss: 0.7156 - val_accuracy: 0.8027\n",
      "Epoch 106/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5958 - accuracy: 0.8327 - val_loss: 0.6216 - val_accuracy: 0.8066\n",
      "Epoch 107/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5868 - accuracy: 0.8314 - val_loss: 0.6489 - val_accuracy: 0.8184\n",
      "Epoch 108/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5419 - accuracy: 0.8509 - val_loss: 0.6294 - val_accuracy: 0.8164\n",
      "Epoch 109/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5787 - accuracy: 0.8327 - val_loss: 0.6824 - val_accuracy: 0.8047\n",
      "Epoch 110/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5413 - accuracy: 0.8542 - val_loss: 0.7304 - val_accuracy: 0.7598\n",
      "Epoch 111/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5274 - accuracy: 0.8503 - val_loss: 0.8489 - val_accuracy: 0.7891\n",
      "Epoch 112/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5749 - accuracy: 0.8320 - val_loss: 0.6830 - val_accuracy: 0.7832\n",
      "Epoch 113/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5841 - accuracy: 0.8444 - val_loss: 0.6487 - val_accuracy: 0.7832\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6018 - accuracy: 0.8262 - val_loss: 0.6814 - val_accuracy: 0.8223\n",
      "Epoch 115/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5186 - accuracy: 0.8451 - val_loss: 0.7362 - val_accuracy: 0.7969\n",
      "Epoch 116/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6165 - accuracy: 0.8372 - val_loss: 0.7154 - val_accuracy: 0.8086\n",
      "Epoch 117/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5248 - accuracy: 0.8542 - val_loss: 0.6368 - val_accuracy: 0.8262\n",
      "Epoch 118/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.4952 - accuracy: 0.8587 - val_loss: 0.6927 - val_accuracy: 0.7969\n",
      "Epoch 119/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6195 - accuracy: 0.8385 - val_loss: 0.6843 - val_accuracy: 0.7988\n",
      "Epoch 120/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5097 - accuracy: 0.8431 - val_loss: 0.7374 - val_accuracy: 0.8164\n",
      "Epoch 121/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6180 - accuracy: 0.8418 - val_loss: 0.6008 - val_accuracy: 0.8066\n",
      "Epoch 122/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6150 - accuracy: 0.8203 - val_loss: 0.7479 - val_accuracy: 0.7793\n",
      "Epoch 123/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5230 - accuracy: 0.8555 - val_loss: 0.6766 - val_accuracy: 0.8066\n",
      "Epoch 124/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6623 - accuracy: 0.8320 - val_loss: 0.5983 - val_accuracy: 0.8047\n",
      "Epoch 125/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6076 - accuracy: 0.8385 - val_loss: 0.7207 - val_accuracy: 0.7949\n",
      "Epoch 126/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5559 - accuracy: 0.8366 - val_loss: 0.7704 - val_accuracy: 0.7891\n",
      "Epoch 127/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6005 - accuracy: 0.8346 - val_loss: 0.6791 - val_accuracy: 0.8086\n",
      "Epoch 128/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5731 - accuracy: 0.8379 - val_loss: 0.7930 - val_accuracy: 0.7676\n",
      "Epoch 129/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6433 - accuracy: 0.8379 - val_loss: 0.6148 - val_accuracy: 0.8047\n",
      "Epoch 130/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6014 - accuracy: 0.8314 - val_loss: 0.8391 - val_accuracy: 0.8262\n",
      "Epoch 131/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5893 - accuracy: 0.8483 - val_loss: 0.7553 - val_accuracy: 0.7891\n",
      "Epoch 132/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5000 - accuracy: 0.8522 - val_loss: 0.6294 - val_accuracy: 0.8086\n",
      "Epoch 133/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5573 - accuracy: 0.8451 - val_loss: 0.6324 - val_accuracy: 0.8145\n",
      "Epoch 134/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6450 - accuracy: 0.8288 - val_loss: 0.6481 - val_accuracy: 0.8027\n",
      "Epoch 135/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5583 - accuracy: 0.8333 - val_loss: 0.6945 - val_accuracy: 0.8066\n",
      "Epoch 136/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5448 - accuracy: 0.8483 - val_loss: 0.6857 - val_accuracy: 0.8164\n",
      "Epoch 137/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6844 - accuracy: 0.8294 - val_loss: 0.6969 - val_accuracy: 0.7930\n",
      "Epoch 138/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6144 - accuracy: 0.8294 - val_loss: 0.5923 - val_accuracy: 0.8145\n",
      "Epoch 139/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5445 - accuracy: 0.8418 - val_loss: 0.6707 - val_accuracy: 0.8086\n",
      "Epoch 140/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5857 - accuracy: 0.8431 - val_loss: 1.1571 - val_accuracy: 0.7031\n",
      "Epoch 141/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5996 - accuracy: 0.8327 - val_loss: 0.7687 - val_accuracy: 0.7773\n",
      "Epoch 142/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6082 - accuracy: 0.8281 - val_loss: 0.6395 - val_accuracy: 0.7871\n",
      "Epoch 143/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5706 - accuracy: 0.8431 - val_loss: 0.6700 - val_accuracy: 0.8047\n",
      "Epoch 144/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6212 - accuracy: 0.8366 - val_loss: 0.6786 - val_accuracy: 0.8027\n",
      "Epoch 145/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5736 - accuracy: 0.8333 - val_loss: 0.7676 - val_accuracy: 0.7773\n",
      "Epoch 146/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6227 - accuracy: 0.8431 - val_loss: 0.6132 - val_accuracy: 0.8359\n",
      "Epoch 147/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5408 - accuracy: 0.8646 - val_loss: 0.7414 - val_accuracy: 0.8184\n",
      "Epoch 148/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5655 - accuracy: 0.8424 - val_loss: 0.5866 - val_accuracy: 0.8320\n",
      "Epoch 149/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5258 - accuracy: 0.8451 - val_loss: 0.8281 - val_accuracy: 0.7500\n",
      "Epoch 150/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6106 - accuracy: 0.8398 - val_loss: 0.7420 - val_accuracy: 0.7988\n",
      "Epoch 151/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6516 - accuracy: 0.8229 - val_loss: 0.6579 - val_accuracy: 0.7988\n",
      "Epoch 152/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6350 - accuracy: 0.8125 - val_loss: 0.8453 - val_accuracy: 0.7930\n",
      "Epoch 153/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6308 - accuracy: 0.8229 - val_loss: 0.7682 - val_accuracy: 0.7676\n",
      "Epoch 154/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6377 - accuracy: 0.8294 - val_loss: 0.7110 - val_accuracy: 0.8105\n",
      "Epoch 155/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5722 - accuracy: 0.8451 - val_loss: 0.7103 - val_accuracy: 0.7949\n",
      "Epoch 156/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6290 - accuracy: 0.8197 - val_loss: 0.9434 - val_accuracy: 0.7695\n",
      "Epoch 157/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6010 - accuracy: 0.8288 - val_loss: 0.6786 - val_accuracy: 0.8008\n",
      "Epoch 158/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5931 - accuracy: 0.8249 - val_loss: 0.6289 - val_accuracy: 0.8047\n",
      "Epoch 159/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5670 - accuracy: 0.8444 - val_loss: 0.7250 - val_accuracy: 0.7969\n",
      "Epoch 160/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5884 - accuracy: 0.8444 - val_loss: 0.7334 - val_accuracy: 0.7871\n",
      "Epoch 161/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6195 - accuracy: 0.8223 - val_loss: 0.7423 - val_accuracy: 0.7891\n",
      "Epoch 162/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6673 - accuracy: 0.8307 - val_loss: 0.8875 - val_accuracy: 0.7324\n",
      "Epoch 163/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7309 - accuracy: 0.8092 - val_loss: 0.7064 - val_accuracy: 0.7812\n",
      "Epoch 164/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6149 - accuracy: 0.8275 - val_loss: 0.5849 - val_accuracy: 0.8105\n",
      "Epoch 165/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5748 - accuracy: 0.8379 - val_loss: 0.9597 - val_accuracy: 0.7129\n",
      "Epoch 166/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6006 - accuracy: 0.8327 - val_loss: 0.6856 - val_accuracy: 0.7871\n",
      "Epoch 167/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5905 - accuracy: 0.8470 - val_loss: 0.7402 - val_accuracy: 0.7988\n",
      "Epoch 168/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6445 - accuracy: 0.8190 - val_loss: 0.6564 - val_accuracy: 0.8281\n",
      "Epoch 169/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6542 - accuracy: 0.8184 - val_loss: 0.5879 - val_accuracy: 0.8242\n",
      "Epoch 170/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5826 - accuracy: 0.8203 - val_loss: 1.0060 - val_accuracy: 0.7793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6719 - accuracy: 0.8294 - val_loss: 0.7473 - val_accuracy: 0.7988\n",
      "Epoch 172/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6782 - accuracy: 0.8151 - val_loss: 0.6061 - val_accuracy: 0.8359\n",
      "Epoch 173/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6744 - accuracy: 0.8288 - val_loss: 0.6722 - val_accuracy: 0.7969\n",
      "Epoch 174/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6691 - accuracy: 0.8327 - val_loss: 0.7175 - val_accuracy: 0.7676\n",
      "Epoch 175/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6040 - accuracy: 0.8203 - val_loss: 0.6771 - val_accuracy: 0.8086\n",
      "Epoch 176/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6336 - accuracy: 0.8301 - val_loss: 0.6498 - val_accuracy: 0.7969\n",
      "Epoch 177/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6710 - accuracy: 0.8229 - val_loss: 0.6288 - val_accuracy: 0.8066\n",
      "Epoch 178/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6914 - accuracy: 0.8210 - val_loss: 0.7220 - val_accuracy: 0.7734\n",
      "Epoch 179/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6750 - accuracy: 0.8229 - val_loss: 0.7537 - val_accuracy: 0.7930\n",
      "Epoch 180/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6143 - accuracy: 0.8262 - val_loss: 0.7116 - val_accuracy: 0.7910\n",
      "Epoch 181/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6589 - accuracy: 0.8203 - val_loss: 0.7193 - val_accuracy: 0.8066\n",
      "Epoch 182/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6384 - accuracy: 0.8197 - val_loss: 0.6601 - val_accuracy: 0.8047\n",
      "Epoch 183/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5976 - accuracy: 0.8359 - val_loss: 0.6649 - val_accuracy: 0.7949\n",
      "Epoch 184/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6536 - accuracy: 0.8223 - val_loss: 0.7880 - val_accuracy: 0.7656\n",
      "Epoch 185/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6324 - accuracy: 0.8203 - val_loss: 0.8502 - val_accuracy: 0.7539\n",
      "Epoch 186/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7398 - accuracy: 0.8034 - val_loss: 0.7228 - val_accuracy: 0.8047\n",
      "Epoch 187/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6026 - accuracy: 0.8359 - val_loss: 0.7529 - val_accuracy: 0.7539\n",
      "Epoch 188/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6950 - accuracy: 0.7943 - val_loss: 0.6807 - val_accuracy: 0.8027\n",
      "Epoch 189/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.5818 - accuracy: 0.8346 - val_loss: 0.7685 - val_accuracy: 0.7891\n",
      "Epoch 190/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6514 - accuracy: 0.8066 - val_loss: 0.7366 - val_accuracy: 0.7832\n",
      "Epoch 191/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7358 - accuracy: 0.8197 - val_loss: 0.7788 - val_accuracy: 0.7734\n",
      "Epoch 192/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6350 - accuracy: 0.8392 - val_loss: 0.6848 - val_accuracy: 0.7852\n",
      "Epoch 193/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6887 - accuracy: 0.8184 - val_loss: 0.7949 - val_accuracy: 0.7793\n",
      "Epoch 194/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6279 - accuracy: 0.8307 - val_loss: 0.8307 - val_accuracy: 0.7871\n",
      "Epoch 195/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.7109 - accuracy: 0.8008 - val_loss: 0.6156 - val_accuracy: 0.8145\n",
      "Epoch 196/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6458 - accuracy: 0.8132 - val_loss: 0.5860 - val_accuracy: 0.7969\n",
      "Epoch 197/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6151 - accuracy: 0.8229 - val_loss: 0.7087 - val_accuracy: 0.7930\n",
      "Epoch 198/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6515 - accuracy: 0.8190 - val_loss: 0.6607 - val_accuracy: 0.8047\n",
      "Epoch 199/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6594 - accuracy: 0.8132 - val_loss: 0.7806 - val_accuracy: 0.7969\n",
      "Epoch 200/200\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.6551 - accuracy: 0.8118 - val_loss: 0.6629 - val_accuracy: 0.7734\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "history = model.fit_generator(\n",
    "    train_generator2, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_i = layers.Input(shape=(28,28,1))\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_i)\n",
    "x = layers.Conv2D(32, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(64, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"valid\",strides=2, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "x = layers.Conv2D(128, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "c = base_model_l(input_i)\n",
    "n = layers.concatenate([x, c])\n",
    "\n",
    "x = layers.Dense(64, activation='relu')(n)\n",
    "\n",
    "output_i = layers.Dense(10, activation = \"softmax\")(x)\n",
    "\n",
    "base_model_i = models.Model(inputs=[input_i], outputs=[output_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = base_model_i\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", \n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "history = model.fit_generator(\n",
    "    train_generator, \n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy=0.86784, Validation accuracy=0.84180\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Train accuracy={max(history.history['accuracy']):.5f}, \" +\n",
    "    f\"Validation accuracy={max(history.history['val_accuracy']):.5f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'],label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'],label='validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
